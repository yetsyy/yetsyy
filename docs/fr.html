<!DOCTYPE html><html lang="es"><head><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Li Carvallo Escudero - Data Scientist</title><meta name="next-head-count" content="3"/><link rel="preload" href="/yetsyy/_next/static/css/2cfbcafd1f432f19.css" as="style"/><link rel="stylesheet" href="/yetsyy/_next/static/css/2cfbcafd1f432f19.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/yetsyy/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/yetsyy/_next/static/chunks/webpack-7778c48bad961dc0.js" defer=""></script><script src="/yetsyy/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/yetsyy/_next/static/chunks/main-c3f8536ac0abdaf5.js" defer=""></script><script src="/yetsyy/_next/static/chunks/pages/_app-2c1fdb7c64b6a093.js" defer=""></script><script src="/yetsyy/_next/static/chunks/pages/%5Blocale%5D-d587e125807600e8.js" defer=""></script><script src="/yetsyy/_next/static/_hWTu7obFamONFEnDvw0V/_buildManifest.js" defer=""></script><script src="/yetsyy/_next/static/_hWTu7obFamONFEnDvw0V/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="bg-cover bg-fixed bg-center min-h-screen text-white" style="background-image:url(/yetsyy/fondo.png)"><div class="bg-black bg-opacity-50 min-h-screen flex flex-col"><main class="container mx-auto p-4 flex-grow pt-20"><div class="flex flex-col items-center justify-center min-h-screen py-2 text-center px-4"><h1 class="text-4xl sm:text-5xl md:text-6xl font-bold leading-tight">Bienvenue sur le Portfolio de Li Carvallo Escudero</h1><p class="mt-3 text-lg sm:text-xl md:text-2xl max-w-2xl">Professionnel de la Science des Données | Spécialiste en Apprentissage Automatique | Passionné(e) de NLP</p></div></main></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"_nextI18Next":{"initialI18nStore":{"fr":{"common":{"about":"À propos","projects":"Projets","contact":"Contact","welcome":"Bienvenue sur le Portfolio de Li Carvallo Escudero","data_scientist":"Professionnel de la Science des Données | Spécialiste en Apprentissage Automatique | Passionné(e) de NLP","download_cv":"Télécharger le CV","linkedin_profile":"Profil LinkedIn","about_me":"À propos de moi","skills":"Compétences","contact_me":"Contactez-moi","contact_me_description":"Toujours disponible pour de nouvelles opportunités et collaborations. N'hésitez pas à me contacter via le formulaire ci-dessous ou à vous connecter avec moi sur LinkedIn.","first_name":"Prénom","last_name":"Nom de famille","email":"Email","message":"Message","send":"Envoyer","connect_on_linkedin":"Connectez-vous avec moi sur LinkedIn","unsupervised_learning_description":"Ce projet met en œuvre un pipeline complet d'apprentissage non supervisé. Il comprend la réduction de la dimensionnalité avec PCA et t-SNE, et la segmentation des données par clustering hiérarchique.","nlp_with_bert_description":"Ce projet démontre une application avancée du Traitement du Langage Naturel (NLP) en utilisant un modèle Transformer (BERT) pour une tâche de classification \"zero-shot\".","model_interpretability_description":"Ce projet aborde l'un des défis les plus importants de la science des données moderne : l'interprétabilité des modèles de \"boîte noire\". Il utilise la bibliothèque LIME (Local Interpretable Model-Agnostic Explanations).","image_classification_description":"Ce projet met en œuvre un Réseau de Neurones Convolutifs (CNN) pour une tâche de classification d'images. Les CNN sont la référence en matière d'analyse de données visuelles.","hyperparameter_tuning_description":"Ce projet démontre l'optimisation d'un modèle d'Apprentissage Automatique (Random Forest) à l'aide de deux bibliothèques de pointe : Optuna et Ray Tune.","classification_with_xgboost_description":"Ce projet présente un pipeline de classification robuste utilisant XGBoost, l'un des algorithmes les plus puissants et les plus populaires pour les problèmes de données tabulaires.","docker_api_description":"Ce projet montre how to create and dockerize a simple API with Python.","r_project_description":"Un projet d'analyse de données utilisant R.","all_rights_reserved":"Tous droits réservés.","about_me_p1":"Mi experiencia inicial en investigación cualitativa y cuantitativa, trabajando en terreno con comunidades para programas del MINVU y estudios de impacto ambiental, me reveló tanto el poder de los datos como las limitaciones de los métodos tradicionales para procesarlos a gran escala. Esta convicción me llevó a dar un paso deliberado hacia la tecnología, primero cursando un Diplomado en Ciencia de Datos para Políticas Públicas en la Pontificia Universidad Católica de Chile para construir una base cuantitativa robusta, y culminando con una intensiva Especialización en Machine Learning, donde adquirí las competencias técnicas para transformar datos en soluciones predictivas de alto impacto.","about_me_p2":"Mi formación técnica me ha dotado de un dominio integral del ciclo de vida de la inteligencia artificial. Poseo competencias avanzadas para el desarrollo de soluciones de IA de extremo a extremo: desde la programación avanzada en Python y la construcción de modelos predictivos (regresión, clasificación, clustering) y de Deep Learning (Redes Neuronales, Transformers). Mi especialización abarca desde el preprocesamiento de datos y la optimización de hiperparámetros, garantizando soluciones escalables, eficientes y mantenibles.","about_me_p3":"Mi propuesta de valor única reside en la fusión de mi rigurosa formación sociológica con mi especialización técnica en IA. Esta combinación me permite no solo construir modelos algorítmicamente complejos, sino también comprender profundamente el contexto social en el que operan. Mi objetivo es aplicar modelos de IA interpretables y éticos para resolver problemas complejos en el sector público y social, asegurando que la tecnología genere un impacto positivo y equitativo. Cuento con capacitación especial en técnicas de Interpretabilidad y Explicabilidad (XAI) con herramientas como LIME y SHAP, lo que me permite auditar, explicar y mitigar sesgos en los modelos, garantizando que las decisiones automatizadas sean justas, transparentes y socialmente responsables."}},"es":{"common":{"about":"Acerca de","projects":"Proyectos","contact":"Contacto","welcome":"Bienvenido al Portafolio de Li Carvallo Escudero","data_scientist":"Profesional de la Ciencia de Datos | Especialista en Machine Learning | Entusiasta de NLP","download_cv":"Descargar CV","linkedin_profile":"Perfil de LinkedIn","about_me":"Sobre Mí","skills":"Habilidades","contact_me":"Contáctame","contact_me_description":"Siempre con disposición a nuevas oportunidades y colaboraciones. No dudes en contactarme a través del siguiente formulario o conectarte conmigo en LinkedIn.","first_name":"Nombre","last_name":"Apellido","email":"Correo Electrónico","message":"Mensaje","send":"Enviar","connect_on_linkedin":"Conéctate conmigo en LinkedIn","unsupervised_learning_description":"Este proyecto implementa un pipeline completo de aprendizaje no supervisado. Incluye la reducción de dimensionalidad con PCA y t-SNE, y la segmentación de datos mediante clustering jerárquico.","nlp_with_bert_description":"Este proyecto demuestra una aplicación avanzada de Procesamiento del Lenguaje Natural (NLP) utilizando un modelo Transformer (BERT) para una tarea de clasificación de 'disparo único' (zero-shot).","model_interpretability_description":"Este proyecto aborda uno de los desafíos más importantes en la ciencia de datos moderna: la interpretabilidad de los modelos de 'caja negra'. Se utiliza la librería LIME (Local Interpretable Model-Agnostic Explanations).","image_classification_description":"Este proyecto implementa una Red Neuronal Convolucional (CNN) para una tarea de clasificación de imágenes. Las CNN son el estándar de oro para el análisis de datos visuales.","hyperparameter_tuning_description":"Este proyecto demuestra la optimización de un modelo de Machine Learning (Random Forest) utilizando dos librerías de vanguardia: Optuna y Ray Tune.","classification_with_xgboost_description":"Este proyecto presenta un pipeline de clasificación robusto utilizando XGBoost, uno de los algoritmos más potentes y populares para problemas de datos tabulares.","docker_api_description":"Este proyecto demuestra cómo crear y 'dockerizar' una API simple con Python.","r_project_description":"Un proyecto de análisis de datos utilizando R.","all_rights_reserved":"Todos los derechos reservados.","about_me_p1":"Mi experiencia inicial en investigación cualitativa y cuantitativa, trabajando en terreno con comunidades para programas del MINVU y estudios de impacto ambiental, me reveló tanto el poder de los datos como las limitaciones de los métodos tradicionales para procesarlos a gran escala. Esta convicción me llevó a dar un paso deliberado hacia la tecnología, primero cursando un Diplomado en Ciencia de Datos para Políticas Públicas en la Pontificia Universidad Católica de Chile para construir una base cuantitativa robusta, y culminando con una intensiva Especialización en Machine Learning, donde adquirí las competencias técnicas para transformar datos en soluciones predictivas de alto impacto.","about_me_p2":"Mi formación técnica me ha dotado de un dominio integral del ciclo de vida de la inteligencia artificial. Poseo competencias avanzadas para el desarrollo de soluciones de IA de extremo a extremo: desde la programación avanzada en Python y la construcción de modelos predictivos (regresión, clasificación, clustering) y de Deep Learning (Redes Neuronales, Transformers). Mi especialización abarca desde el preprocesamiento de datos y la optimización de hiperparámetros, garantizando soluciones escalables, eficientes y mantenibles.","about_me_p3":"Mi propuesta de valor única reside en la fusión de mi rigurosa formación sociológica con mi especialización técnica en IA. Esta combinación me permite no solo construir modelos algorítmicamente complejos, sino también comprender profundamente el contexto social en el que operan. Mi objetivo es aplicar modelos de IA interpretables y éticos para resolver problemas complejos en el sector público y social, asegurando que la tecnología genere un impacto positivo y equitativo. Cuento con capacitación especial en técnicas de Interpretabilidad y Explicabilidad (XAI) con herramientas como LIME y SHAP, lo que me permite auditar, explicar y mitigar sesgos en los modelos, garantizando que las decisiones automatizadas sean justas, transparentes y socialmente responsables."}}},"initialLocale":"fr","ns":["common"],"userConfig":{"i18n":{"defaultLocale":"es","locales":["en","fr","es","pt"]},"react":{"useSuspense":false},"default":{"i18n":{"defaultLocale":"es","locales":["en","fr","es","pt"]},"react":{"useSuspense":false}}}}},"__N_SSG":true},"page":"/[locale]","query":{"locale":"fr"},"buildId":"_hWTu7obFamONFEnDvw0V","assetPrefix":"/yetsyy","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>